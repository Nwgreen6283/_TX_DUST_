---
title: "ENV_COP_DUST"
format:
  html:
    theme: default
---

**This code combines clean data sets (dust, copies, and env)**

# Getting Started

#### Libraries

```{r, include = FALSE}
library(tidyverse)
library(here)
library(Hmisc) #Lag Function
```

#### Load Clean Data

```{r, include = FALSE}
dust<- readRDS(here("data", "processed_data", "dust", "dust_final.rds")) #Clean dust data
copies<- read_csv(here("data", "processed_data", "qpcr", "total_clean_copies.csv")) #Clean Copies Data
env<- read_csv(here("data", "processed_data", "env", "ysi_2.csv")) #Clean Environmental Data
dust_perm<- read_csv(here("data", "processed_data", "dust", "dust_master.csv")) #Dust permutations
cfu<- read_rds(here("data", "processed_data", "cfu", "cfu.rds")) #CFU Data
hf<- read_csv(here("data", "processed_data", "qpcr", "hf183", "bo_hf183.csv")) #HF183
sp<- read_csv(here("data", "processed_data", "qpcr", "species_all.csv")) #Species
tot_bac<- read_csv(here("data", "processed_data", "qpcr", "total_bacteria.csv")) #Total Bacteria
tss<- read_csv(here("data", "processed_data", "env", "tss.csv"))
```

# Further Cleaning

#### Drop NAs from Environmental Data

```{r}
env<- env %>%
  filter(!date == as.Date('2022-02-16') | !site == "RD") %>% #Gets rid of NA
  select(1:20) #Removes NA columns
```

#### Combine data sets: (1) Dust, (2) Total Vib, (3) Environmental, (4) CFU, (5) Species

```{r}
master<- #env %>% 
  dust %>% full_join(copies)

master<-
  master %>%
  full_join(env)

master<-
  master %>%
  full_join(cfu)

master<-
  master %>%
  full_join(hf)

master<- 
  master %>%
  full_join(sp)

master<-
  master %>%
  full_join(tot_bac)

master<- 
  master %>%
  full_join(tss)

```

#### Create VAI

Create Cell Equivalents by dividing sample copies per mL by average 16S rDNA for Total Vibrio (9 copies) and Total Bacteria (3.5)

```{r}
# Total Vibrio CE
master <- 
  master %>%
  mutate(
    VAI = ((copies_mL / 9) / (tot_bacteria / 3.5)))
  
```

#### Clean Data Again

We will get warnings since we have dust data for the whole year, but Nutrient and Copies_mL data for just the monthly and daily time series. This is ok.

```{r}
master<- master %>%
  select(!c(...1, type))  %>% #Gets rid of number column from excel
  mutate(
    sal = as.numeric(master$sal), #Set character columns as numeric
    temp = as.numeric(master$temp),
    do_mgl = as.numeric(master$do_mgl),
    do_per = as.numeric(master$do_per),
    pH = as.numeric(master$pH),
    secchi = as.numeric(master$secchi),
    amm = as.numeric(master$amm),
    nn = as.numeric(master$nn),
    orthop = as.numeric(master$orthop),
    sil = as.numeric(master$sil),
    din_dip = as.numeric(master$din_dip),
    tdn = as.numeric(master$tdn),
    don = as.numeric(master$don),
    doc = as.numeric(master$doc),
    toc = as.numeric(master$toc),
    tn = as.numeric(master$tn),
    date = as.Date(date)) %>%
    mutate(site = recode(site, "BO" = "Blind Oso", #Rename Site Columns
                             "C2" = "Canals",
                            "RD" = "Gulf"))
```

#### 

## DAILY Site-specific data frames

#### Trim Dates

```{r}
master2<-
  master %>%
  filter(date %in% as.Date('2022-07-05') : as.Date('2022-07-19'))
```

#### Add Dust permutations DF

```{r}
master2<-
  master2 %>% full_join(dust_perm) %>%
  filter(hr_cst %in% "01") %>% #Gets rid of duplicates
  select(!c(Dust, SUM, Type, t1, t7, t13, t19, tsum, tavg, t7avg, hr_cst)) %>% #Get rid of var
  rename("dust" = "t7sum")
```

#### Site-specific Dataframes + Lag

```{r}
bo<- 
  master2 %>%
  filter(site %in% "Blind Oso"| date %in% c( as.Date("2022-07-05"), as.Date("2022-07-06"))) %>%
  select(!site) %>% 
  mutate(dust_lag =Lag(dust, shift  = 1)) %>% #Lag from cca.qmd
  filter(date %in% as.Date('2022-07-07') : as.Date('2022-07-19')) 
c2<- 
  master2 %>%
  filter(site %in% "Canals"| date %in% c( as.Date("2022-07-05"), as.Date("2022-07-06"))) %>%
  select(!site) %>% 
  mutate(dust_lag =Lag(dust, shift  = 2)) %>%
  filter(date %in% as.Date('2022-07-07') : as.Date('2022-07-19')) 
rd<- 
  master2 %>%
  filter(site %in% "Gulf"| date %in% c( as.Date("2022-07-05"), as.Date("2022-07-06"))) %>%
  select(!site) %>% 
  mutate(dust_lag =Lag(dust, shift  = 1)) %>%
  filter(date %in% as.Date('2022-07-07') : as.Date('2022-07-19')) 
```

## MONTHLY Site-specific data frames

#### Select Monthly Dates

Also including 7/18/23 to represent July

```{r}
monthly<-
  master %>%
  filter(Type %in% "Monthly" | date %in% as.Date('2022-07-18'),
         hr_cst %in% c("00","01")) #Gets rid of duplicates
```

#### Site-specific DF

```{r}
bo_m<-
  monthly %>%
  filter(site %in% "Blind Oso") %>%
  select(!c(site, hr_cst))

c2_m<-
  monthly %>%
  filter(site %in% "Canals") %>%
  select(!c(site, hr_cst))

rd_m<-
  monthly %>%
  filter(site %in% "Gulf") %>%
  select(!c(site, hr_cst))
  
```

# Save CSV

```{r}
#MASTER
write.csv(master,file= here("data","processed_data","tx_master.csv")) 

#[DAILY]

#BLIND OSO
write.csv(bo,file= here("data","processed_data","bo_master_daily.csv"))

#CANALS
write.csv(c2,file= here("data","processed_data","c2_master_daily.csv"))

#GULF
write.csv(rd,file= here("data","processed_data","rd_master_daily.csv"))

#[MONTHLY]

#BLIND OSO
write.csv(bo_m,file= here("data","processed_data","bo_master_monthly.csv"))

#CANALS
write.csv(c2_m,file= here("data","processed_data","c2_master_monthly.csv"))

#GULF
write.csv(rd_m,file= here("data","processed_data","rd_master_monthly.csv"))
```
